"""
ì±„íŒ… ê´€ë ¨ API ì—”ë“œí¬ì¸íŠ¸
Ollama ëª¨ë¸ê³¼ì˜ ëŒ€í™”, ì„¸ì…˜ ê´€ë¦¬ ë“±ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import logging
import json
import requests
from fastapi import APIRouter, HTTPException, Request
from fastapi.responses import StreamingResponse
from typing import Dict, Any, Optional
from src.models.schemas import ChatRequest, SessionInfo
from src.utils.session_manager import (
    get_or_create_session,
    add_message_to_session,
    get_session,
    delete_session,
    get_all_sessions,
    build_conversation_prompt
)

from datetime import datetime

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/chat", tags=["Chat"])

# Ollama ì„œë²„ ì„¤ì •
OLLAMA_BASE_URL = "http://1.237.52.240:11434"

# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
AVAILABLE_MODELS = [
    {"name": "gemma3:12b-it-qat", "size": "8.9 GB", "id": "5d4fa005e7bb"},
    {"name": "llama3.1:8b", "size": "4.9 GB", "id": "46e0c10c039e"},
    {"name": "llama3.2-vision:11b-instruct-q4_K_M", "size": "7.8 GB", "id": "6f2f9757ae97"},    
    {"name": "qwen3:14b-q8_0", "size": "15 GB", "id": "304bf7349c71"},
    {"name": "deepseek-r1:14b", "size": "9.0 GB", "id": "c333b7232bdb"},
    {"name": "deepseek-v2:16b-lite-chat-q8_0", "size": "16 GB", "id": "1d62ef756269"},        
]

# ì›¹ ê²€ìƒ‰ ëª¨ë“œ ì €ì¥ì†Œ (ì‹¤ì œ ìš´ì˜ì—ì„œëŠ” Redisë‚˜ ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© ê¶Œì¥)
web_search_mode = "model_only"  # ê¸°ë³¸ê°’

def get_web_search_mode():
    """í˜„ì¬ ì›¹ ê²€ìƒ‰ ëª¨ë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return web_search_mode

def set_web_search_mode(mode: str):
    """ì›¹ ê²€ìƒ‰ ëª¨ë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    global web_search_mode
    web_search_mode = mode



async def perform_mcp_search_with_decision(query: str, service_decision: Dict[str, Any], model_name: Optional[str] = None) -> str:
    """
    ì´ë¯¸ ê²°ì •ëœ ì„œë¹„ìŠ¤ íƒ€ì…ì„ ì‚¬ìš©í•˜ì—¬ MCP ì„œë²„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        service_decision: ì´ë¯¸ ê²°ì •ëœ ì„œë¹„ìŠ¤ ê²°ì • ê²°ê³¼
        model_name: ì‚¬ìš©í•  AI ëª¨ë¸ ì´ë¦„ (Noneì´ë©´ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©)
    
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¬¸ìì—´
    """
    try:
        # ì´ë¯¸ ê²°ì •ëœ ì„œë¹„ìŠ¤ íƒ€ì…ì— ë”°ë¼ ì ì ˆí•œ MCP ì„œë¹„ìŠ¤ í˜¸ì¶œ
        decision = service_decision.get("decision", "MODEL_ONLY")
        
        if decision == "MCP_SERVER-STOCK":
            return await perform_stock_search(query, model_name)
        elif decision == "MCP_SERVER-WEATHER":
            return await perform_weather_search(query)
        elif decision == "MCP_SERVER-WEB":
            return await perform_web_search(query)
        else:
            # ê¸°ë³¸ì ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
            return await perform_web_search(query)
                
    except Exception as e:
        logger.error(f"MCP ì„œë²„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return f"MCP ì„œë²„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"


async def perform_mcp_search(query: str, model_name: Optional[str] = None) -> str:
    """
    MCP ì„œë²„ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§€ëŠ¥ì ì¸ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    Langchain decision ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì ì ˆí•œ ì„œë¹„ìŠ¤ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        model_name: ì‚¬ìš©í•  AI ëª¨ë¸ ì´ë¦„ (Noneì´ë©´ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©)
    
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¬¸ìì—´
    """
    try:
        # 1ë‹¨ê³„: Langchain decision ì„œë¹„ìŠ¤ë¡œ ì„œë¹„ìŠ¤ ë¶„ë¥˜ (ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë¸ ì‚¬ìš©)
        from src.services.langchain_decision_service import langchain_decision_service
        service_decision = langchain_decision_service.decide_search_method(query, "mcp_server", model_name)
        
        # 2ë‹¨ê³„: ë¶„ë¥˜ëœ ì„œë¹„ìŠ¤ì— ë”°ë¼ ì ì ˆí•œ MCP ì„œë¹„ìŠ¤ í˜¸ì¶œ
        return await perform_mcp_search_with_decision(query, service_decision, model_name)
                
    except Exception as e:
        logger.error(f"MCP ì„œë²„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return f"MCP ì„œë²„ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"



async def perform_stock_search(query: str, model_name: Optional[str] = None) -> str:
    """
    ì£¼ì‹ ê´€ë ¨ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        model_name: ì‚¬ìš©í•  AI ëª¨ë¸ ì´ë¦„ (Noneì´ë©´ ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©)
    
    Returns:
        ì£¼ì‹ ê²€ìƒ‰ ê²°ê³¼
    """
    try:
        from src.services.stock_keyword_extractor import stock_keyword_extractor
        
        # í†µí•© ë©”ì„œë“œë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ â†’ ê²€ìƒ‰ â†’ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë¸ ì‚¬ìš©)
        result = await stock_keyword_extractor.extract_and_get_stock_info(query, model_name)
        
        if not result.get('success', False):
            return f"âŒ ì£¼ì‹ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
        
        # ê²°ê³¼ êµ¬ì„±
        results = []
        results.append(f"ğŸ“ˆ ì£¼ì‹ ì •ë³´ ê²€ìƒ‰ ê²°ê³¼:")
        
        # ì¶”ì¶œ ì •ë³´
        extraction_result = result.get('extraction_result', {})
        extracted_keyword = extraction_result.get('keyword', '')
        results.append(f"ğŸ” ì¶”ì¶œëœ í‚¤ì›Œë“œ: '{extracted_keyword}' (ì‹ ë¢°ë„: {extraction_result.get('confidence', 0):.1%})")
        
        # ì²˜ë¦¬ ë°©ì‹ì— ë”°ë¥¸ ê²°ê³¼ í‘œì‹œ
        processing_type = result.get('processing_type', '')
        
        if processing_type == 'direct_stock_code':
            # ì£¼ì‹ ì½”ë“œë¡œ ì§ì ‘ ì¡°íšŒí•œ ê²½ìš°
            stock_info = result.get('stock_info', {})
            if stock_info and stock_info.get('success', True):
                basic_info = stock_info.get('Basic Information', {})
                financial_data = stock_info.get('Financial Data', {})
                
                results.append(f"\nğŸ”¸ ì¢…ëª©ì½”ë“œ: {extracted_keyword}")
                results.append(f"   íšŒì‚¬ëª…: {basic_info.get('Company Name', 'N/A')}")
                results.append(f"   ì‹œì¥: {basic_info.get('Listed Market', 'N/A')}")
                results.append(f"   ì—…ì¢…: {basic_info.get('Industry Classification', 'N/A')}")
                results.append(f"   í˜„ì¬ê°€: {financial_data.get('Latest Stock Price', 'N/A'):,}ì›" if isinstance(financial_data.get('Latest Stock Price'), (int, float)) else f"   í˜„ì¬ê°€: {financial_data.get('Latest Stock Price', 'N/A')}")
                results.append(f"   PER: {financial_data.get('Price-Earnings Ratio', 'N/A')}")
                results.append(f"   PBR: {financial_data.get('Price-Book Ratio', 'N/A')}")
                results.append(f"   ë°°ë‹¹ìˆ˜ìµë¥ : {financial_data.get('Dividend Yield', 'N/A')}%")
            else:
                error_msg = stock_info.get('error', 'ì¡°íšŒ ì‹¤íŒ¨') if isinstance(stock_info, dict) else 'ì¡°íšŒ ì‹¤íŒ¨'
                results.append(f"\nâŒ ì¢…ëª©ì½”ë“œ {extracted_keyword}: {error_msg}")
                
        elif processing_type == 'keyword_search_then_detail':
            # í‚¤ì›Œë“œ ê²€ìƒ‰ í›„ ìƒì„¸ ì •ë³´ ì¡°íšŒí•œ ê²½ìš°
            search_results = result.get('search_results', {})
            stock_info = result.get('stock_info', {})
            selected_stock_code = result.get('selected_stock_code', '')
            selected_stock_name = result.get('selected_stock_name', '')
            
            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
            results.append(f"\nğŸ” '{extracted_keyword}' ê²€ìƒ‰ ê²°ê³¼ ({search_results.get('result_count', 0)}ê°œ):")
            results.append(f"ğŸ“‹ ì„ íƒëœ ì¢…ëª©: {selected_stock_name} ({selected_stock_code})")
            
            # ìƒì„¸ ì •ë³´
            if stock_info and stock_info.get('success', True):
                basic_info = stock_info.get('Basic Information', {})
                financial_data = stock_info.get('Financial Data', {})
                
                results.append(f"\nğŸ”¸ ìƒì„¸ ì •ë³´:")
                results.append(f"   íšŒì‚¬ëª…: {basic_info.get('Company Name', 'N/A')}")
                results.append(f"   ì‹œì¥: {basic_info.get('Listed Market', 'N/A')}")
                results.append(f"   ì—…ì¢…: {basic_info.get('Industry Classification', 'N/A')}")
                results.append(f"   í˜„ì¬ê°€: {financial_data.get('Latest Stock Price', 'N/A'):,}ì›" if isinstance(financial_data.get('Latest Stock Price'), (int, float)) else f"   í˜„ì¬ê°€: {financial_data.get('Latest Stock Price', 'N/A')}")
                results.append(f"   PER: {financial_data.get('Price-Earnings Ratio', 'N/A')}")
                results.append(f"   PBR: {financial_data.get('Price-Book Ratio', 'N/A')}")
                results.append(f"   ë°°ë‹¹ìˆ˜ìµë¥ : {financial_data.get('Dividend Yield', 'N/A')}%")
            else:
                error_msg = stock_info.get('error', 'ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨') if isinstance(stock_info, dict) else 'ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨'
                results.append(f"\nâŒ ìƒì„¸ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {error_msg}")
            
            # ë‚˜ë¨¸ì§€ ê²€ìƒ‰ ê²°ê³¼ë„ í‘œì‹œ
            if search_results.get("results"):
                for i, stock in enumerate(search_results["results"][1:5], 2):
                    results.append(f"\n{i}. {stock.get('company_name', 'N/A')} ({stock.get('stock_code', 'N/A')})")
                    results.append(f"   ì‹œì¥: {stock.get('market', 'N/A')}")
        
        # ì¶”ì¶œ ì •ë³´ ì¶”ê°€
        results.append(f"\nğŸ“‹ ì¶”ì¶œ ì •ë³´:")
        results.append(f"   ì›ë³¸ ì§ˆë¬¸: {extraction_result.get('original_prompt', 'N/A')}")
        results.append(f"   ì¶”ì¶œ ë°©ì‹: {extraction_result.get('extraction_type', 'N/A')}")
        results.append(f"   ì²˜ë¦¬ ë°©ì‹: {processing_type}")
        if extraction_result.get('reason'):
            results.append(f"   ì¶”ì¶œ ì´ìœ : {extraction_result.get('reason', 'N/A')}")
        
        return "\n".join(results)
        
    except Exception as e:
        logger.error(f"ì£¼ì‹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return f"ì£¼ì‹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

async def perform_weather_search(query: str) -> str:
    """
    ë‚ ì”¨ ê´€ë ¨ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
    
    Returns:
        ë‚ ì”¨ ê²€ìƒ‰ ê²°ê³¼
    """
    try:
        from src.services.integrated_mcp_client import safe_mcp_call, OptimizedIntegratedMCPClient
        
        # ë„ì‹œëª… ì¶”ì¶œ
        cities = ["ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì œì£¼", "ìˆ˜ì›", "ê³ ì–‘"]
        found_city = None
        
        for city in cities:
            if city in query:
                found_city = city
                break
        
        if not found_city:
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì„œìš¸ ì‚¬ìš©
            found_city = "ì„œìš¸"
        
        async with OptimizedIntegratedMCPClient() as client:
            results = []
            results.append(f"ğŸŒ¤ï¸ {found_city} ë‚ ì”¨ ì •ë³´:")
            
            try:
                weather_info = await safe_mcp_call(client, client.get_weather, found_city)
                if weather_info:
                    results.append(f"\nğŸŒ¡ï¸ í˜„ì¬ì˜¨ë„: {weather_info.get('temperature', 'N/A')}Â°C")
                    results.append(f"ğŸ’§ ìŠµë„: {weather_info.get('humidity', 'N/A')}%")
                    results.append(f"ğŸŒªï¸ í’ì†: {weather_info.get('wind_speed', 'N/A')}m/s")
                    results.append(f"â˜ï¸ ë‚ ì”¨ìƒíƒœ: {weather_info.get('description', 'N/A')}")
                    
                    # ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ë„ ì¶”ê°€
                    try:
                        air_quality = await safe_mcp_call(client, client.get_air_quality, found_city)
                        if air_quality:
                            results.append(f"ğŸ˜· ë¯¸ì„¸ë¨¼ì§€: {air_quality.get('pm10', 'N/A')}ã/ã¥")
                            results.append(f"ğŸ˜· ì´ˆë¯¸ì„¸ë¨¼ì§€: {air_quality.get('pm25', 'N/A')}ã/ã¥")
                    except:
                        pass  # ë¯¸ì„¸ë¨¼ì§€ ì •ë³´ê°€ ì—†ì–´ë„ ê³„ì† ì§„í–‰
                else:
                    results.append(f"\nâŒ {found_city} ë‚ ì”¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                results.append(f"\nâŒ ë‚ ì”¨ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            
            return "\n".join(results)
            
    except Exception as e:
        logger.error(f"ë‚ ì”¨ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return f"ë‚ ì”¨ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

async def perform_web_search(query: str) -> str:
    """
    ì›¹ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
    
    Returns:
        ì›¹ ê²€ìƒ‰ ê²°ê³¼
    """
    try:
        from src.services.integrated_mcp_client import safe_mcp_call, OptimizedIntegratedMCPClient
        
        async with OptimizedIntegratedMCPClient() as client:
            # ì›¹ ê²€ìƒ‰ ìˆ˜í–‰
            search_results = await safe_mcp_call(
                client, 
                client.web_search, 
                query, 
                max_results=5
            )
            
            if search_results and "results" in search_results:
                results = []
                results.append(f"ğŸ” '{query}' ì›¹ ê²€ìƒ‰ ê²°ê³¼:")
                
                for i, result in enumerate(search_results["results"][:5], 1):
                    title = result.get("title", "ì œëª© ì—†ìŒ")
                    snippet = result.get("snippet", "ë‚´ìš© ì—†ìŒ")
                    url = result.get("url", "")
                    
                    results.append(f"\n{i}. {title}")
                    results.append(f"   {snippet}")
                    if url:
                        results.append(f"   ğŸ”— {url}")
                
                return "\n".join(results)
            else:
                return f"'{query}'ì— ëŒ€í•œ ì›¹ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                
    except Exception as e:
        logger.error(f"ì›¹ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return f"ì›¹ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def extract_search_keywords(query: str) -> str:
    """
    ì‚¬ìš©ì ì¿¼ë¦¬ì—ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        query: ì‚¬ìš©ì ì¿¼ë¦¬
    
    Returns:
        ê²€ìƒ‰ í‚¤ì›Œë“œ
    """
    # ì¼ë°˜ì ì¸ ê²€ìƒ‰ ìš”ì²­ íŒ¨í„´ ì œê±°
    search_patterns = [
        "ìµœì‹ ", "ë‰´ìŠ¤", "ì°¾ì•„ì¤˜", "ê²€ìƒ‰í•´ì¤˜", "ì•Œë ¤ì¤˜", "ë³´ì—¬ì¤˜",
        "ê´€ë ¨", "ì •ë³´", "ì†Œì‹", "ì—…ë°ì´íŠ¸", "ìµœê·¼"
    ]
    
    keywords = query
    for pattern in search_patterns:
        keywords = keywords.replace(pattern, "").strip()
    
    # ì—°ì†ëœ ê³µë°± ì œê±°
    import re
    keywords = re.sub(r'\s+', ' ', keywords)
    
    return keywords.strip()

@router.post("/")
async def chat(request: ChatRequest):
    """
    Ollama ëª¨ë¸ê³¼ ëŒ€í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        request: ì±„íŒ… ìš”ì²­ (ëª¨ë¸, ë©”ì‹œì§€, ì„¸ì…˜ ID ë“± í¬í•¨)
    
    Returns:
        ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ë˜ëŠ” ì¼ë°˜ ì‘ë‹µ
    """
    try:
        # ì„¸ì…˜ ê´€ë¦¬
        session = get_or_create_session(request.session_id)
        
        # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€
        add_message_to_session(session.session_id, "user", request.message, request.model)
        
        # ì›¹ ê²€ìƒ‰ ëª¨ë“œì— ë”°ë¥¸ ì²˜ë¦¬
        current_mode = get_web_search_mode()
        enhanced_message = request.message
        
        # "ëª¨ë¸ì—ì„œë§Œ ë‹µë³€" ëª¨ë“œì¼ ë•Œë§Œ langchain decision ìŠ¤í‚µ
        if current_mode == "model_only":
            logger.info("ëª¨ë¸ì—ì„œë§Œ ë‹µë³€ ëª¨ë“œ: langchain decision ìŠ¤í‚µ")
        else:
            # Langchain decision ì„œë¹„ìŠ¤ë¡œ ë¶„ì„ ìˆ˜í–‰ (ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë¸ ì‚¬ìš©)
            from src.services.langchain_decision_service import langchain_decision_service
            service_decision = langchain_decision_service.decide_search_method(
                request.message, 
                current_mode, 
                model_name=request.model
            )
            logger.info(f"ì„œë¹„ìŠ¤ ê²°ì •: {service_decision}")
            
            if current_mode == "mcp_server" and service_decision["decision"].startswith("MCP_SERVER-"):
                # MCP ì„œë²„ ê²€ìƒ‰ ìˆ˜í–‰ (ì´ë¯¸ ê²°ì •ëœ ì„œë¹„ìŠ¤ íƒ€ì… ì‚¬ìš©)
                try:
                    mcp_results = await perform_mcp_search_with_decision(request.message, service_decision, request.model)
                    if mcp_results:
                        enhanced_message = f"{request.message}\n\n[MCP ì„œë²„ ê²€ìƒ‰ ê²°ê³¼]\n{mcp_results}"
                        logger.info(f"MCP ì„œë²„ ê²€ìƒ‰ ìˆ˜í–‰ë¨: {service_decision['reason']} ({service_decision['decision']})")
                    else:
                        logger.info("MCP ì„œë²„ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                except Exception as e:
                    logger.error(f"MCP ì„œë²„ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    enhanced_message = f"{request.message}\n\n[MCP ì„œë²„ ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}]"
            elif current_mode == "mcp_server" and not service_decision["decision"].startswith("MCP_SERVER-"):
                logger.info(f"MCP ì„œë²„ ê²€ìƒ‰ ìŠ¤í‚µë¨: {service_decision['reason']} ({service_decision['decision']})")
        
        # ëŒ€í™” í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        conversation_prompt = build_conversation_prompt(
            session.session_id, 
            enhanced_message, 
            request.system
        )
        
        # Ollama API í˜¸ì¶œ
        ollama_url = f"{OLLAMA_BASE_URL}/api/generate"
        payload = {
            "model": request.model,
            "prompt": conversation_prompt,
            "stream": True,
            "options": request.options or {}
        }
        
        def generate():
            """ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„±"""
            try:
                response = requests.post(ollama_url, json=payload, stream=True)
                response.raise_for_status()
                
                full_response = ""
                for line in response.iter_lines():
                    if line:
                        data = json.loads(line.decode('utf-8'))
                        if data.get('done', False):
                            # ì‘ë‹µì—ì„œ "Assistant:" ì ‘ë‘ì‚¬ ì œê±°
                            cleaned_response = full_response
                            if full_response.startswith("Assistant:"):
                                cleaned_response = full_response.replace("Assistant:", "").strip()
                            
                            # ì‘ë‹µ ì™„ë£Œ ì‹œ ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ì— ì¶”ê°€
                            add_message_to_session(
                                session.session_id, 
                                "assistant", 
                                cleaned_response, 
                                request.model
                            )
                            break
                        
                        if 'response' in data:
                            chunk = data['response']
                            full_response += chunk
                            yield f"data: {json.dumps({'response': chunk})}\n\n"
                
                # ìµœì¢… ì‘ë‹µ ì „ì†¡
                yield f"data: {json.dumps({'done': True})}\n\n"
                
            except Exception as e:
                logger.error(f"Ollama API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
                error_response = f"data: {json.dumps({'error': f'AI ëª¨ë¸ ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'})}\n\n"
                yield error_response
        
        return StreamingResponse(generate(), media_type="text/plain")
        
    except Exception as e:
        logger.error(f"ì±„íŒ… ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì±„íŒ… ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.post("/analyze-request")
async def analyze_chat_request(request: ChatRequest):
    """
    ì±„íŒ… ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì„œë¹„ìŠ¤ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
    Langchain decision ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
    
    Args:
        request: ì±„íŒ… ìš”ì²­ (ëª¨ë¸, ë©”ì‹œì§€, ì„¸ì…˜ ID ë“± í¬í•¨)
    
    Returns:
        ë¶„ì„ ê²°ê³¼ (ì„œë¹„ìŠ¤ ê²°ì •, ì´ìœ , ì‹ ë¢°ë„ ë“±)
    
    Raises:
        HTTPException: ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí•œ ê²½ìš°
    """
    try:
        # í˜„ì¬ ì›¹ ê²€ìƒ‰ ëª¨ë“œ ê°€ì ¸ì˜¤ê¸°
        current_mode = get_web_search_mode()
        
        # Langchain decision ì„œë¹„ìŠ¤ë¡œ ë¶„ì„ (ì‚¬ìš©ìê°€ ì„ íƒí•œ ëª¨ë¸ ì‚¬ìš©)
        from src.services.langchain_decision_service import langchain_decision_service
        service_decision = langchain_decision_service.decide_search_method(
            request.message, 
            current_mode, 
            model_name=request.model
        )
        
        # ë¶„ì„ ê²°ê³¼ êµ¬ì„±
        result = {
            "chat_request": {
                "message": request.message,
                "model": request.model,
                "session_id": request.session_id
            },
            "analysis": {
                "current_mode": current_mode,
                "decision": service_decision["decision"],
                "reason": service_decision["reason"],
                "confidence": service_decision["confidence"],
                "use_mcp_server": service_decision["decision"].startswith("MCP_SERVER-"),
                "use_web_search": service_decision["decision"] == "MCP_SERVER-WEB",
                "use_stock_service": service_decision["decision"] == "MCP_SERVER-STOCK",
                "use_weather_service": service_decision["decision"] == "MCP_SERVER-WEATHER",
                "service_type": langchain_decision_service.get_service_type(service_decision)
            },
            "timestamp": datetime.now().isoformat()
        }
        
        return result
        
    except Exception as e:
        logger.error(f"ìš”ì²­ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(
            status_code=500, 
            detail=f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
        )

@router.get("/models")
async def get_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Returns:
        ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
    """
    try:
        # Ollama ì„œë²„ì—ì„œ ì‹¤ì œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹œë„
        try:
            response = requests.get(f"{OLLAMA_BASE_URL}/api/tags")
            if response.status_code == 200:
                models_data = response.json()
                models = models_data.get('models', [])
                return {"models": models}
        except Exception as e:
            logger.warning(f"Ollama ì„œë²„ì—ì„œ ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ëª¨ë¸ ëª©ë¡ ë°˜í™˜
        return {"models": AVAILABLE_MODELS}
        
    except Exception as e:
        logger.error(f"ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ëª¨ë¸ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@router.get("/sessions")
async def get_sessions():
    """
    ëª¨ë“  ì„¸ì…˜ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Returns:
        ì„¸ì…˜ ì •ë³´ ëª©ë¡
    """
    try:
        sessions = get_all_sessions()
        return {"sessions": sessions}
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ì„¸ì…˜ ëª©ë¡ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@router.get("/sessions/{session_id}")
async def get_session_info(session_id: str):
    """
    íŠ¹ì • ì„¸ì…˜ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    Args:
        session_id: ì¡°íšŒí•  ì„¸ì…˜ ID
    
    Returns:
        ì„¸ì…˜ ì •ë³´
    
    Raises:
        HTTPException: ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš°
    """
    try:
        session = get_session(session_id)
        if not session:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return {"session": session}
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ì„¸ì…˜ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@router.delete("/sessions/{session_id}")
async def delete_session_endpoint(session_id: str):
    """
    ì„¸ì…˜ì„ ì‚­ì œí•©ë‹ˆë‹¤.
    
    Args:
        session_id: ì‚­ì œí•  ì„¸ì…˜ ID
    
    Returns:
        ì‚­ì œ ê²°ê³¼
    """
    try:
        success = delete_session(session_id)
        if success:
            return {"message": "ì„¸ì…˜ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}
        else:
            raise HTTPException(status_code=404, detail="ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ì‚­ì œ ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ì„¸ì…˜ ì‚­ì œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@router.post("/sessions")
async def create_session_endpoint():
    """
    ìƒˆë¡œìš´ ì„¸ì…˜ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    Returns:
        ìƒì„±ëœ ì„¸ì…˜ ì •ë³´
    """
    try:
        session = get_or_create_session()
        return {
            "session_id": session.session_id,
            "created_at": session.created_at,
            "message": "ìƒˆ ì„¸ì…˜ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
    except Exception as e:
        logger.error(f"ì„¸ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail="ì„¸ì…˜ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

@router.get("/health")
async def health_check():
    """
    ì±„íŒ… ì„œë¹„ìŠ¤ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    
    Returns:
        ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´
    """
    try:
        # Ollama ì„œë²„ ì—°ê²° ìƒíƒœ í™•ì¸
        ollama_status = "unknown"
        try:
            response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
            ollama_status = "connected" if response.status_code == 200 else "error"
        except Exception:
            ollama_status = "disconnected"
        
        # ì„¸ì…˜ í†µê³„
        from src.utils.session_manager import get_session_stats
        session_stats = get_session_stats()
        
        health_info = {
            "status": "healthy",
            "timestamp": "2024-01-01T12:00:00Z",
            "ollama_server": ollama_status,
            "ollama_url": OLLAMA_BASE_URL,
            "session_stats": session_stats,
            "available_models": len(AVAILABLE_MODELS)
        }
        return health_info
    except Exception as e:
        logger.error(f"í—¬ìŠ¤ ì²´í¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "status": "unhealthy",
            "timestamp": "2024-01-01T12:00:00Z",
            "error": str(e)
        } 
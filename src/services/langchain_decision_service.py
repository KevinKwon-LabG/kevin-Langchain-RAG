"""
Langchain Decision Service with RAG Integration
ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì„œë¹„ìŠ¤ë¥¼ ê²°ì •í•˜ëŠ” ì„œë¹„ìŠ¤ (RAG í†µí•©)
"""

import logging
import json
from typing import Dict, Any, Optional, Literal
from langchain_ollama import OllamaLLM
from langchain.schema import HumanMessage, SystemMessage
from langchain.prompts import ChatPromptTemplate
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
import os
from enum import Enum

# RAG ì„œë¹„ìŠ¤ import
from src.services.rag_service import rag_service

logger = logging.getLogger(__name__)

# ë””ë²„ê·¸ ë¡œê¹…ì„ ìœ„í•œ ì¶”ê°€ ë¡œê±°
debug_logger = logging.getLogger("langchain_decision_debug")
debug_logger.setLevel(logging.DEBUG)

class DecisionCategory(Enum):
    WEATHER = "weather"
    KOREAN_STOCK = "korean_stock"
    WEB_SEARCH_NEEDED = "web_search_needed"
    DIRECT_ANSWER = "direct_answer"


class LangchainDecisionService:
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì„œë¹„ìŠ¤ë¥¼ ê²°ì •í•˜ëŠ” ì„œë¹„ìŠ¤ (RAG í†µí•©)
    """
    
    def __init__(self, model_name: str = "gemma3:12b-it-qat"):
        """
        Langchain ê¸°ë°˜ ì˜ì‚¬ê²°ì • ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (RAG í†µí•©)
        
        Args:
            model_name: ì‚¬ìš©í•  Ollama ëª¨ë¸ëª…
        """
        self.model_name = model_name
        self.llm = OllamaLLM(
            model=model_name,
            temperature=0.1,
            base_url="http://1.237.52.240:11434"  # env.settingsì˜ OLLAMA_BASE_URLê³¼ ë™ì¼
        )
        
        # RAG í†µí•© ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.decision_prompt_with_rag = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ 4ê°€ì§€ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ê³ , ê°€ëŠ¥í•œ ê²½ìš° ì§ì ‘ ë‹µë³€ë„ ì œê³µí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë¶„ë¥˜ ê¸°ì¤€:
1. weather (ë‚ ì”¨): ë‚ ì”¨, ê¸°ì˜¨, ê°•ìˆ˜, ë‚ ì”¨ ì˜ˆë³´, ê¸°í›„, ì˜¤ëŠ˜ ë‚ ì”¨, ë‚´ì¼ ë‚ ì”¨, ì„œìš¸ ë‚ ì”¨ ë“±ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸
2. korean_stock (í•œêµ­ ì£¼ì‹): í•œêµ­ ì£¼ì‹, KOSPI, KOSDAQ, íŠ¹ì • ì¢…ëª© ì£¼ê°€, ì£¼ì‹ ì‹œì¥, ì¢…ëª©ì½”ë“œ ë“±ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸
3. web_search_needed (ì›¹ ê²€ìƒ‰ í•„ìš”): ìµœì‹  ì •ë³´, ìµœì‹  ê¸°ì‚¬, ìµœì‹  ë‰´ìŠ¤, ì‹¤ì‹œê°„ ë°ì´í„°, íŠ¹ì • ì‚¬ì´íŠ¸ ì •ë³´, í˜„ì¬ ì‹œì ì˜ êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸
4. direct_answer (ë°”ë¡œ ë‹µë³€ ê°€ëŠ¥): ì¼ë°˜ì ì¸ ì§€ì‹, ê°œë… ì„¤ëª…, ì—­ì‚¬ì  ì‚¬ì‹¤, ê³µì‹ ë“± AIê°€ ê°€ì§„ ì •ë³´ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸

ì¤‘ìš”: ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ì€ í•­ìƒ "weather"ë¡œ ë¶„ë¥˜í•˜ì„¸ìš”. "ì˜¤ëŠ˜ ë‚ ì”¨", "ì„œìš¸ ë‚ ì”¨", "ë‚ ì”¨ ì–´ë•Œ", "ê¸°ì˜¨", "ë¹„", "ëˆˆ", "ë§‘ìŒ", "íë¦¼" ë“±ì˜ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ weatherë¡œ ë¶„ë¥˜í•´ì•¼ í•©ë‹ˆë‹¤.

ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ê´€ë ¨ ë¬¸ì„œ ì •ë³´:
{rag_context}

ì‚¬ìš©ì ì§ˆë¬¸: {user_prompt}

ìœ„ ê¸°ì¤€ê³¼ ì°¸ê³  ë¬¸ì„œ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

ë¶„ë¥˜: [weather/korean_stock/web_search_needed/direct_answer]
ë‹µë³€: [ì°¸ê³  ë¬¸ì„œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ êµ¬ì²´ì ì¸ ë‹µë³€, ê°€ëŠ¥í•œ ê²½ìš°]

ë§Œì•½ ì°¸ê³  ë¬¸ì„œì—ì„œ ì •í™•í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
ë‹µë³€í•  ìˆ˜ ì—†ëŠ” ê²½ìš°ì—ëŠ” "í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  í‘œì‹œí•´ì£¼ì„¸ìš”.
""")
        
        # ê¸°ì¡´ ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (RAG ì—†ì´)
        self.decision_prompt = ChatPromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ 4ê°€ì§€ ì¹´í…Œê³ ë¦¬ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë¶„ë¥˜ ê¸°ì¤€:
1. ë‚ ì”¨ ê´€ë ¨ ì •ë³´ ìš”ì²­: ë‚ ì”¨, ê¸°ì˜¨, ê°•ìˆ˜, ë‚ ì”¨ ì˜ˆë³´, ê¸°í›„ ë“±ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸
2. í•œêµ­ ì£¼ì‹ ì‹œì¥ ì¢…ëª© ì£¼ê°€ ì •ë³´ ìš”ì²­: í•œêµ­ ì£¼ì‹, KOSPI, KOSDAQ, íŠ¹ì • ì¢…ëª© ì£¼ê°€, ì£¼ì‹ ì‹œì¥ ë“±ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸
3. ì›¹ ê²€ìƒ‰ í•„ìš”: ìµœì‹  ì •ë³´, ìµœì‹  ê¸°ì‚¬, ìµœì‹  ë‰´ìŠ¤, ì‹¤ì‹œê°„ ë°ì´í„°, íŠ¹ì • ì‚¬ì´íŠ¸ ì •ë³´, í˜„ì¬ ì‹œì ì˜ êµ¬ì²´ì ì¸ ì •ë³´ê°€ í•„ìš”í•œ ì§ˆë¬¸
4. ë°”ë¡œ ë‹µë³€ ê°€ëŠ¥: ì¼ë°˜ì ì¸ ì§€ì‹, ê°œë… ì„¤ëª…, ì—­ì‚¬ì  ì‚¬ì‹¤, ê³µì‹ ë“± AIê°€ ê°€ì§„ ì •ë³´ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸

ì‚¬ìš©ì ì§ˆë¬¸: {user_prompt}

ìœ„ ê¸°ì¤€ì— ë”°ë¼ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:
- weather: ë‚ ì”¨ ê´€ë ¨ ì •ë³´ ìš”ì²­
- korean_stock: í•œêµ­ ì£¼ì‹ ì‹œì¥ ì¢…ëª© ì£¼ê°€ ì •ë³´ ìš”ì²­  
- web_search_needed: ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•œ ì§ˆë¬¸
- direct_answer: ë°”ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸

ë¶„ë¥˜ ê²°ê³¼ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš” (ì˜ˆ: weather, korean_stock, web_search_needed, direct_answer)
""")
        
        # ì‘ë‹µ ë©”ì‹œì§€ ë§¤í•‘
        self.response_messages = {
            DecisionCategory.WEATHER: "ë‚ ì”¨ ì •ë³´ë¥¼ ìš”ì²­í•˜ì…¨ìŠµë‹ˆë‹¤.",
            DecisionCategory.KOREAN_STOCK: "í•œêµ­ ì£¼ì‹ ì‹œì¥ì— ìƒì¥ë˜ì–´ ìˆëŠ” ì¢…ëª©ì˜ ì£¼ê°€ ê´€ë ¨ ì •ë³´ë¥¼ ìš”ì²­í•˜ì…¨ìŠµë‹ˆë‹¤.",
            DecisionCategory.WEB_SEARCH_NEEDED: "ì •í™•í•œ ë‹µë³€ì„ ìœ„í•´ì„œëŠ” ì›¹ ê²€ìƒ‰ì´ í•„ìš”í•©ë‹ˆë‹¤.",
            DecisionCategory.DIRECT_ANSWER: "ë°”ë¡œ ë‹µë³€ë“œë¦¬ê² ìŠµë‹ˆë‹¤"
        }
        
        # RAG í†µí•© Langchain ì²´ì¸ êµ¬ì„±
        self.chain_with_rag = (
            {"user_prompt": RunnablePassthrough(), "rag_context": RunnablePassthrough()}
            | self.decision_prompt_with_rag
            | self.llm
            | StrOutputParser()
        )
        
        # ê¸°ì¡´ Langchain ì²´ì¸ êµ¬ì„± (RAG ì—†ì´)
        self.chain = (
            {"user_prompt": RunnablePassthrough()}
            | self.decision_prompt
            | self.llm
            | StrOutputParser()
        )
    
    def _get_rag_context_for_decision(self, user_prompt: str, top_k: int = 3) -> str:
        """
        ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ RAG ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
        
        Args:
            user_prompt: ì‚¬ìš©ì ì§ˆë¬¸
            top_k: ê²€ìƒ‰í•  ë¬¸ì„œ ìˆ˜
            
        Returns:
            str: RAG ì»¨í…ìŠ¤íŠ¸
        """
        try:
            debug_logger.debug(f"ğŸ” ì˜ì‚¬ê²°ì •ì„ ìœ„í•œ RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹œì‘: {user_prompt}")
            
            # RAG ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
            rag_context = rag_service.retrieve_context(user_prompt, top_k=top_k)
            
            if rag_context:
                debug_logger.debug(f"âœ… RAG ì»¨í…ìŠ¤íŠ¸ ë°œê²¬ (ê¸¸ì´: {len(rag_context)} ë¬¸ì)")
                # ì»¨í…ìŠ¤íŠ¸ë¥¼ ê°„ë‹¨íˆ ìš”ì•½í•˜ì—¬ ì˜ì‚¬ê²°ì •ì— í™œìš©
                return f"ê´€ë ¨ ë¬¸ì„œ ì •ë³´: {rag_context[:500]}..."
            else:
                debug_logger.debug("âš ï¸ ê´€ë ¨ RAG ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ")
                return "ê´€ë ¨ ë¬¸ì„œ ì •ë³´: ì—†ìŒ"
                
        except Exception as e:
            debug_logger.error(f"âŒ RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return "ê´€ë ¨ ë¬¸ì„œ ì •ë³´: ê²€ìƒ‰ ì‹¤íŒ¨"
    
    def _parse_rag_response(self, response: str) -> tuple[str, str]:
        """
        RAG ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ ë¶„ë¥˜ì™€ ë‹µë³€ì„ ë¶„ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            response: RAG ëª¨ë¸ì˜ ì‘ë‹µ
            
        Returns:
            tuple[str, str]: (ë¶„ë¥˜, ë‹µë³€)
        """
        try:
            response = response.strip()
            
            # ë¶„ë¥˜ ì¶”ì¶œ
            classification = ""
            if "ë¶„ë¥˜:" in response:
                classification_part = response.split("ë¶„ë¥˜:")[1].split("\n")[0].strip()
                classification = classification_part.lower()
            
            # ë‹µë³€ ì¶”ì¶œ
            answer = ""
            if "ë‹µë³€:" in response:
                answer_part = response.split("ë‹µë³€:")[1].strip()
                answer = answer_part
            
            debug_logger.debug(f"ğŸ” ì‘ë‹µ íŒŒì‹± - ë¶„ë¥˜: '{classification}', ë‹µë³€ ê¸¸ì´: {len(answer)}")
            
            return classification, answer
            
        except Exception as e:
            debug_logger.error(f"âŒ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            return "", ""
    
    async def classify_prompt(self, user_prompt: str, use_rag: bool = True) -> str:
        """
        ì‚¬ìš©ìì˜ promptë¥¼ ë¶„ë¥˜í•˜ê³  í•´ë‹¹í•˜ëŠ” ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ë°˜í™˜ (RAG í†µí•©)
        
        Args:
            user_prompt: ì‚¬ìš©ìê°€ ì…ë ¥í•œ prompt
            use_rag: RAG ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            
        Returns:
            str: ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¥¸ ì‘ë‹µ ë©”ì‹œì§€ ë˜ëŠ” ì§ì ‘ ë‹µë³€
        """
        try:
            debug_logger.debug(f"ğŸ” ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„ ì‹œì‘ (RAG ì‚¬ìš©: {use_rag}): {user_prompt}")
            
            if use_rag:
                # RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
                rag_context = self._get_rag_context_for_decision(user_prompt)
                
                # RAG í†µí•© Langchainì„ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜ ë° ë‹µë³€ ìƒì„±
                debug_logger.debug("ğŸ¤– RAG í†µí•© Langchain ì²´ì¸ ì‹¤í–‰ ì¤‘...")
                result = await self.chain_with_rag.ainvoke({
                    "user_prompt": user_prompt,
                    "rag_context": rag_context
                })
                debug_logger.debug(f"ğŸ“Š RAG í†µí•© ì›ë³¸ ê²°ê³¼: '{result}'")
                
                # ê²°ê³¼ íŒŒì‹± (ë¶„ë¥˜ì™€ ë‹µë³€ ë¶„ë¦¬)
                classification_result, direct_answer = self._parse_rag_response(result)
                debug_logger.debug(f"ğŸ§¹ íŒŒì‹±ëœ ë¶„ë¥˜: '{classification_result}', ë‹µë³€: '{direct_answer[:100]}...'")
                
                # ì§ì ‘ ë‹µë³€ì´ ìˆëŠ” ê²½ìš° ë°˜í™˜
                if direct_answer and direct_answer.strip() and "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in direct_answer:
                    debug_logger.debug("âœ… RAG ê¸°ë°˜ ì§ì ‘ ë‹µë³€ ì œê³µ")
                    return direct_answer
                
            else:
                # ê¸°ì¡´ Langchainì„ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜ ìˆ˜í–‰
                debug_logger.debug("ğŸ¤– ê¸°ì¡´ Langchain ì²´ì¸ ì‹¤í–‰ ì¤‘...")
                classification_result = await self.chain.ainvoke(user_prompt)
                debug_logger.debug(f"ğŸ“Š ê¸°ì¡´ ì›ë³¸ ë¶„ë¥˜ ê²°ê³¼: '{classification_result}'")
                classification_result = classification_result.strip().lower()
            
            # ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¥¸ ì‘ë‹µ ë©”ì‹œì§€ ë°˜í™˜
            if "weather" in classification_result:
                debug_logger.debug("ğŸŒ¤ï¸ ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë¨")
                return self.response_messages[DecisionCategory.WEATHER]
            elif "korean_stock" in classification_result or "stock" in classification_result:
                debug_logger.debug("ğŸ“ˆ í•œêµ­ ì£¼ì‹ ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë¨")
                return self.response_messages[DecisionCategory.KOREAN_STOCK]
            elif "web_search" in classification_result or "search" in classification_result:
                debug_logger.debug("ğŸ” ì›¹ ê²€ìƒ‰ í•„ìš” ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë¨")
                return self.response_messages[DecisionCategory.WEB_SEARCH_NEEDED]
            elif "direct_answer" in classification_result or "direct" in classification_result:
                debug_logger.debug("ğŸ’¬ ë°”ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë¨")
                return self.response_messages[DecisionCategory.DIRECT_ANSWER]
            else:
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ í•„ìš”ë¡œ ë¶„ë¥˜
                debug_logger.debug("â“ ë¶„ë¥˜ ë¶ˆê°€ëŠ¥, ê¸°ë³¸ê°’(ì›¹ ê²€ìƒ‰)ìœ¼ë¡œ ì„¤ì •")
                return self.response_messages[DecisionCategory.WEB_SEARCH_NEEDED]
                
        except Exception as e:
            debug_logger.error(f"âŒ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            logger.error(f"ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return self.response_messages[DecisionCategory.WEB_SEARCH_NEEDED]
    
    def classify_prompt_sync(self, user_prompt: str, use_rag: bool = True) -> str:
        """
        ë™ê¸° ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©ìì˜ promptë¥¼ ë¶„ë¥˜í•˜ê³  í•´ë‹¹í•˜ëŠ” ì‘ë‹µ ë©”ì‹œì§€ë¥¼ ë°˜í™˜ (RAG í†µí•©)
        
        Args:
            user_prompt: ì‚¬ìš©ìê°€ ì…ë ¥í•œ prompt
            use_rag: RAG ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            
        Returns:
            str: ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¥¸ ì‘ë‹µ ë©”ì‹œì§€ ë˜ëŠ” ì§ì ‘ ë‹µë³€
        """
        try:
            debug_logger.debug(f"ğŸ” ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„ ì‹œì‘ (ë™ê¸°, RAG ì‚¬ìš©: {use_rag}): {user_prompt}")
            
            if use_rag:
                # RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
                rag_context = self._get_rag_context_for_decision(user_prompt)
                
                # RAG í†µí•© Langchainì„ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜ ë° ë‹µë³€ ìƒì„±
                debug_logger.debug("ğŸ¤– RAG í†µí•© Langchain ì²´ì¸ ì‹¤í–‰ ì¤‘ (ë™ê¸°)...")
                result = self.chain_with_rag.invoke({
                    "user_prompt": user_prompt,
                    "rag_context": rag_context
                })
                debug_logger.debug(f"ğŸ“Š RAG í†µí•© ì›ë³¸ ê²°ê³¼ (ë™ê¸°): '{result}'")
                
                # ê²°ê³¼ íŒŒì‹± (ë¶„ë¥˜ì™€ ë‹µë³€ ë¶„ë¦¬)
                classification_result, direct_answer = self._parse_rag_response(result)
                debug_logger.debug(f"ğŸ§¹ íŒŒì‹±ëœ ë¶„ë¥˜ (ë™ê¸°): '{classification_result}', ë‹µë³€: '{direct_answer[:100]}...'")
                
                # ì§ì ‘ ë‹µë³€ì´ ìˆëŠ” ê²½ìš° ë°˜í™˜
                if direct_answer and direct_answer.strip() and "ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" not in direct_answer:
                    debug_logger.debug("âœ… RAG ê¸°ë°˜ ì§ì ‘ ë‹µë³€ ì œê³µ (ë™ê¸°)")
                    return direct_answer
                
            else:
                # ê¸°ì¡´ Langchainì„ ì‚¬ìš©í•˜ì—¬ ë¶„ë¥˜ ìˆ˜í–‰
                debug_logger.debug("ğŸ¤– ê¸°ì¡´ Langchain ì²´ì¸ ì‹¤í–‰ ì¤‘ (ë™ê¸°)...")
                classification_result = self.chain.invoke(user_prompt)
                debug_logger.debug(f"ğŸ“Š ê¸°ì¡´ ì›ë³¸ ë¶„ë¥˜ ê²°ê³¼ (ë™ê¸°): '{classification_result}'")
                classification_result = classification_result.strip().lower()
            
            # ë¶„ë¥˜ ê²°ê³¼ì— ë”°ë¥¸ ì‘ë‹µ ë©”ì‹œì§€ ë°˜í™˜
            if "weather" in classification_result:
                debug_logger.debug("ğŸŒ¤ï¸ ë‚ ì”¨ ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë¨ (ë™ê¸°)")
                return self.response_messages[DecisionCategory.WEATHER]
            elif "korean_stock" in classification_result or "stock" in classification_result:
                debug_logger.debug("ğŸ“ˆ í•œêµ­ ì£¼ì‹ ê´€ë ¨ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë¨ (ë™ê¸°)")
                return self.response_messages[DecisionCategory.KOREAN_STOCK]
            elif "web_search" in classification_result or "search" in classification_result:
                debug_logger.debug("ğŸ” ì›¹ ê²€ìƒ‰ í•„ìš” ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë¨ (ë™ê¸°)")
                return self.response_messages[DecisionCategory.WEB_SEARCH_NEEDED]
            elif "direct_answer" in classification_result or "direct" in classification_result:
                debug_logger.debug("ğŸ’¬ ë°”ë¡œ ë‹µë³€ ê°€ëŠ¥í•œ ì§ˆë¬¸ìœ¼ë¡œ ë¶„ë¥˜ë¨ (ë™ê¸°)")
                return self.response_messages[DecisionCategory.DIRECT_ANSWER]
            else:
                # ê¸°ë³¸ê°’ìœ¼ë¡œ ì›¹ ê²€ìƒ‰ í•„ìš”ë¡œ ë¶„ë¥˜
                debug_logger.debug("â“ ë¶„ë¥˜ ë¶ˆê°€ëŠ¥, ê¸°ë³¸ê°’(ì›¹ ê²€ìƒ‰)ìœ¼ë¡œ ì„¤ì • (ë™ê¸°)")
                return self.response_messages[DecisionCategory.WEB_SEARCH_NEEDED]
                
        except Exception as e:
            debug_logger.error(f"âŒ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (ë™ê¸°): {e}")
            logger.error(f"ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return self.response_messages[DecisionCategory.WEB_SEARCH_NEEDED]
    
    async def classify_prompt_with_metadata(self, user_prompt: str, use_rag: bool = True) -> Dict[str, Any]:
        """
        ì‚¬ìš©ìì˜ promptë¥¼ ë¶„ë¥˜í•˜ê³  ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ê²°ê³¼ë¥¼ ë°˜í™˜ (RAG í†µí•©)
        
        Args:
            user_prompt: ì‚¬ìš©ìê°€ ì…ë ¥í•œ prompt
            use_rag: RAG ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
            
        Returns:
            Dict[str, Any]: ë¶„ë¥˜ ê²°ê³¼ì™€ ë©”íƒ€ë°ì´í„°
        """
        try:
            debug_logger.debug(f"ğŸ” ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„ ì‹œì‘ (ë©”íƒ€ë°ì´í„° í¬í•¨, RAG ì‚¬ìš©: {use_rag}): {user_prompt}")
            
            rag_context = ""
            if use_rag:
                # RAG ì»¨í…ìŠ¤íŠ¸ ê²€ìƒ‰
                rag_context = self._get_rag_context_for_decision(user_prompt)
            
            # ë¶„ë¥˜ ìˆ˜í–‰
            classification_result = await self.classify_prompt(user_prompt, use_rag)
            
            # ë©”íƒ€ë°ì´í„° êµ¬ì„±
            metadata = {
                "user_prompt": user_prompt,
                "classification_result": classification_result,
                "use_rag": use_rag,
                "rag_context_length": len(rag_context) if rag_context else 0,
                "rag_context_preview": rag_context[:200] + "..." if len(rag_context) > 200 else rag_context,
                "model_used": self.model_name,
                "timestamp": "2024-01-01T12:00:00"  # ì‹¤ì œë¡œëŠ” datetime.now().isoformat() ì‚¬ìš©
            }
            
            return metadata
            
        except Exception as e:
            debug_logger.error(f"âŒ ë©”íƒ€ë°ì´í„° í¬í•¨ ë¶„ë¥˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {
                "user_prompt": user_prompt,
                "classification_result": self.response_messages[DecisionCategory.WEB_SEARCH_NEEDED],
                "use_rag": use_rag,
                "error": str(e),
                "model_used": self.model_name,
                "timestamp": "2024-01-01T12:00:00"
            }


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
langchain_decision_service = LangchainDecisionService() 
#!/usr/bin/env python3
"""
í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
.env íŒŒì¼ì„ ìƒì„±í•˜ê³  ê¸°ë³¸ ì„¤ì •ì„ ì ìš©í•©ë‹ˆë‹¤.
"""

import os
import sys
from pathlib import Path

def create_env_file():
    """env.settings íŒŒì¼ ìƒì„±"""
    project_root = Path(__file__).parent.parent
    env_file = project_root / "env.settings"
    
    if env_file.exists():
        print("âš ï¸  env.settings íŒŒì¼ì´ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
        response = input("ë®ì–´ì“°ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
        if response.lower() != 'y':
            print("ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
            return False
    
    try:
        # ê¸°ë³¸ env.settings ë‚´ìš© ìƒì„±
        content = """# =============================================================================
# ì„œë²„ ì„¤ì •
# =============================================================================
HOST=0.0.0.0
PORT=11040
DEBUG=true
LOG_LEVEL=INFO

# =============================================================================
# Ollama ì„¤ì •
# =============================================================================
OLLAMA_BASE_URL=http://1.237.52.240:11434
OLLAMA_TIMEOUT=120
OLLAMA_MAX_RETRIES=3

# =============================================================================
# ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
# =============================================================================
CHROMA_PERSIST_DIRECTORY=data/vectorstore
EMBEDDING_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DEVICE=cpu

# =============================================================================
# ë¬¸ì„œ ì²˜ë¦¬ ì„¤ì •
# =============================================================================
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_TOKENS=4000
UPLOAD_FOLDER=data/documents
MAX_FILE_SIZE=16777216
ALLOWED_EXTENSIONS=.pdf,.txt,.docx,.md

# =============================================================================
# LLM ëª¨ë¸ ì„¤ì • (ê¸°ë³¸ê°’)
# =============================================================================
DEFAULT_MODEL=gemma3:12b-it-qat
DEFAULT_TEMPERATURE=0.7
DEFAULT_TOP_P=0.9
DEFAULT_TOP_K=40
DEFAULT_REPEAT_PENALTY=1.1
DEFAULT_SEED=-1

# =============================================================================
# RAG ì„¤ì •
# =============================================================================
DEFAULT_USE_RAG=true
DEFAULT_TOP_K_DOCUMENTS=5
DEFAULT_SIMILARITY_THRESHOLD=0.7

# =============================================================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì„¤ì •
# =============================================================================
DEFAULT_SYSTEM_PROMPT=You are a helpful assistant. Answer questions based on the provided context. If you cannot find relevant information in the context, say so clearly.
RAG_SYSTEM_PROMPT=You are a helpful assistant. Use the provided context to answer questions accurately. If the context doesn't contain relevant information, say "ì»¨í…ìŠ¤íŠ¸ì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

# =============================================================================
# ì„¸ì…˜ ê´€ë¦¬ ì„¤ì •
# =============================================================================
MAX_SESSION_AGE_HOURS=24
MAX_MESSAGES_PER_SESSION=100
SESSION_CLEANUP_INTERVAL_HOURS=6

# =============================================================================
# ê³ ê¸‰ ì„¤ì • - Temperature ë²”ìœ„
# =============================================================================
TEMPERATURE_MIN=0.0
TEMPERATURE_MAX=2.0
TEMPERATURE_STEP=0.1
TEMPERATURE_PRESETS=0.1,0.3,0.5,0.7,0.9,1.0,1.2

# =============================================================================
# ê³ ê¸‰ ì„¤ì • - Top P ë²”ìœ„
# =============================================================================
TOP_P_MIN=0.1
TOP_P_MAX=1.0
TOP_P_STEP=0.05
TOP_P_PRESETS=0.1,0.3,0.5,0.7,0.9,1.0

# =============================================================================
# ê³ ê¸‰ ì„¤ì • - Top K ë²”ìœ„
# =============================================================================
TOP_K_MIN=1
TOP_K_MAX=100
TOP_K_STEP=1
TOP_K_PRESETS=10,20,40,60,80,100

# =============================================================================
# ê³ ê¸‰ ì„¤ì • - ìµœëŒ€ í† í° ìˆ˜ ë²”ìœ„
# =============================================================================
MAX_TOKENS_MIN=100
MAX_TOKENS_MAX=8192
MAX_TOKENS_STEP=100
MAX_TOKENS_PRESETS=1024,2048,4096,6144,8192

# =============================================================================
# ê³ ê¸‰ ì„¤ì • - Repeat Penalty ë²”ìœ„
# =============================================================================
REPEAT_PENALTY_MIN=1.0
REPEAT_PENALTY_MAX=2.0
REPEAT_PENALTY_STEP=0.1
REPEAT_PENALTY_PRESETS=1.0,1.1,1.2,1.3,1.5,1.8

# =============================================================================
# ê³ ê¸‰ ì„¤ì • - RAG ê´€ë ¨ ë²”ìœ„
# =============================================================================
RAG_TOP_K_MIN=1
RAG_TOP_K_MAX=20
RAG_TOP_K_STEP=1
RAG_TOP_K_PRESETS=3,5,7,10,15,20

# =============================================================================
# ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ (JSON í˜•ì‹)
# =============================================================================
AVAILABLE_MODELS=[
  {"name": "gemma3:12b-it-qat", "size": "8.9 GB", "id": "5d4fa005e7bb", "description": "Googleì˜ Gemma 3 12B ëª¨ë¸ (ì–‘ìí™”ë¨)"},
  {"name": "llama3.1:8b", "size": "4.9 GB", "id": "46e0c10c039e", "description": "Metaì˜ Llama 3.1 8B ëª¨ë¸"},
  {"name": "llama3.2-vision:11b-instruct-q4_K_M", "size": "7.8 GB", "id": "6f2f9757ae97", "description": "Metaì˜ Llama 3.2 Vision 11B ëª¨ë¸"},
  {"name": "qwen3:14b-q8_0", "size": "15 GB", "id": "304bf7349c71", "description": "Alibabaì˜ Qwen 3 14B ëª¨ë¸"},
  {"name": "deepseek-r1:14b", "size": "9.0 GB", "id": "c333b7232bdb", "description": "DeepSeekì˜ R1 14B ëª¨ë¸"},
  {"name": "deepseek-v2:16b-lite-chat-q8_0", "size": "16 GB", "id": "1d62ef756269", "description": "DeepSeekì˜ V2 16B Lite ëª¨ë¸"}
]

# =============================================================================
# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (JSON í˜•ì‹)
# =============================================================================
SYSTEM_PROMPT_TEMPLATES=[
  {"name": "ê¸°ë³¸", "prompt": "You are a helpful assistant. Answer questions based on the provided context. If you cannot find relevant information in the context, say so clearly."},
  {"name": "í•œêµ­ì–´", "prompt": "ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” í•œêµ­ì–´ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì œê³µëœ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”. ì»¨í…ìŠ¤íŠ¸ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° ëª…í™•íˆ ë§ì”€í•´ ì£¼ì„¸ìš”."},
  {"name": "ì½”ë”©", "prompt": "You are a helpful programming assistant. Provide clear, well-documented code examples and explanations. Always consider best practices and security."},
  {"name": "ë²ˆì—­", "prompt": "You are a professional translator. Provide accurate and natural translations while preserving the original meaning and context."},
  {"name": "ìš”ì•½", "prompt": "You are a summarization expert. Provide concise, accurate summaries that capture the key points and main ideas."},
  {"name": "ë¶„ì„", "prompt": "You are an analytical assistant. Provide detailed analysis with supporting evidence and logical reasoning."}
]

# =============================================================================
# ë³´ì•ˆ ì„¤ì •
# =============================================================================
CORS_ALLOW_ORIGINS=*
CORS_ALLOW_CREDENTIALS=true
CORS_ALLOW_METHODS=GET,POST,PUT,DELETE,OPTIONS
CORS_ALLOW_HEADERS=*

# =============================================================================
# ë¡œê¹… ì„¤ì •
# =============================================================================
LOG_FILE=logs/app.log
LOG_MAX_SIZE=10485760
LOG_BACKUP_COUNT=5
LOG_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s
"""
        
        with open(env_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print("âœ… env.settings íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
        
    except Exception as e:
        print(f"âŒ .env íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        return False

def customize_env_file():
    """ì‚¬ìš©ì ì…ë ¥ì„ ë°›ì•„ env.settings íŒŒì¼ì„ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ"""
    project_root = Path(__file__).parent.parent
    env_file = project_root / "env.settings"
    
    if not env_file.exists():
        print("âŒ env.settings íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”.")
        return False
    
    print("\nğŸ”§ í™˜ê²½ ë³€ìˆ˜ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ")
    print("=" * 50)
    
    try:
        with open(env_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ì„œë²„ ì„¤ì •
        print("\nğŸ“¡ ì„œë²„ ì„¤ì •")
        host = input(f"í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: 0.0.0.0): ").strip() or "0.0.0.0"
        port = input(f"í¬íŠ¸ (ê¸°ë³¸ê°’: 11040): ").strip() or "11040"
        
        # Ollama ì„¤ì •
        print("\nğŸ¤– Ollama ì„¤ì •")
        ollama_url = input(f"Ollama ì„œë²„ URL (ê¸°ë³¸ê°’: http://1.237.52.240:11434): ").strip() or "http://1.237.52.240:11434"
        
        # ê¸°ë³¸ ëª¨ë¸ ì„¤ì •
        print("\nğŸ¯ ê¸°ë³¸ ëª¨ë¸ ì„¤ì •")
        default_model = input(f"ê¸°ë³¸ ëª¨ë¸ (ê¸°ë³¸ê°’: gemma3:12b-it-qat): ").strip() or "gemma3:12b-it-qat"
        
        # RAG ì„¤ì •
        print("\nğŸ“š RAG ì„¤ì •")
        use_rag = input(f"ê¸°ë³¸ì ìœ¼ë¡œ RAG ì‚¬ìš© (ê¸°ë³¸ê°’: true): ").strip() or "true"
        top_k_docs = input(f"ê¸°ë³¸ ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜ (ê¸°ë³¸ê°’: 5): ").strip() or "5"
        
        # ê³ ê¸‰ ì„¤ì •
        print("\nâš™ï¸  ê³ ê¸‰ ì„¤ì •")
        temperature = input(f"ê¸°ë³¸ Temperature (ê¸°ë³¸ê°’: 0.7): ").strip() or "0.7"
        top_p = input(f"ê¸°ë³¸ Top P (ê¸°ë³¸ê°’: 0.9): ").strip() or "0.9"
        max_tokens = input(f"ê¸°ë³¸ ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸ê°’: 4000): ").strip() or "4000"
        
        # ì„¤ì • ì ìš©
        content = content.replace("HOST=0.0.0.0", f"HOST={host}")
        content = content.replace("PORT=11040", f"PORT={port}")
        content = content.replace("OLLAMA_BASE_URL=http://1.237.52.240:11434", f"OLLAMA_BASE_URL={ollama_url}")
        content = content.replace("DEFAULT_MODEL=gemma3:12b-it-qat", f"DEFAULT_MODEL={default_model}")
        content = content.replace("DEFAULT_USE_RAG=true", f"DEFAULT_USE_RAG={use_rag}")
        content = content.replace("DEFAULT_TOP_K_DOCUMENTS=5", f"DEFAULT_TOP_K_DOCUMENTS={top_k_docs}")
        content = content.replace("DEFAULT_TEMPERATURE=0.7", f"DEFAULT_TEMPERATURE={temperature}")
        content = content.replace("DEFAULT_TOP_P=0.9", f"DEFAULT_TOP_P={top_p}")
        content = content.replace("MAX_TOKENS=4000", f"MAX_TOKENS={max_tokens}")
        
        with open(env_file, 'w', encoding='utf-8') as f:
            f.write(content)
        
        print("\nâœ… env.settings íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆë˜ì—ˆìŠµë‹ˆë‹¤.")
        return True
        
    except Exception as e:
        print(f"âŒ í™˜ê²½ ë³€ìˆ˜ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ ì‹¤íŒ¨: {e}")
        return False

def validate_env_file():
    """í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ê²€ì¦"""
    project_root = Path(__file__).parent.parent
    env_file = project_root / "env.settings"
    
    if not env_file.exists():
        print("âŒ env.settings íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return False
    
    try:
        with open(env_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # í•„ìˆ˜ ì„¤ì • í™•ì¸
        required_vars = [
            "HOST", "PORT", "OLLAMA_BASE_URL", "DEFAULT_MODEL",
            "DEFAULT_TEMPERATURE", "DEFAULT_TOP_P", "MAX_TOKENS"
        ]
        
        missing_vars = []
        for var in required_vars:
            if f"{var}=" not in content:
                missing_vars.append(var)
        
        if missing_vars:
            print(f"âŒ í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {', '.join(missing_vars)}")
            return False
        
        print("âœ… í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ì´ ìœ íš¨í•©ë‹ˆë‹¤.")
        return True
        
    except Exception as e:
        print(f"âŒ í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ ê²€ì¦ ì‹¤íŒ¨: {e}")
        return False

def show_current_config():
    """í˜„ì¬ ì„¤ì • í‘œì‹œ"""
    project_root = Path(__file__).parent.parent
    env_file = project_root / "env.settings"
    
    if not env_file.exists():
        print("âŒ env.settings íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    try:
        with open(env_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        print("\nğŸ“‹ í˜„ì¬ env.settings ì„¤ì •")
        print("=" * 50)
        
        lines = content.split('\n')
        for line in lines:
            line = line.strip()
            if line and not line.startswith('#') and '=' in line:
                key, value = line.split('=', 1)
                print(f"{key}: {value}")
        
    except Exception as e:
        print(f"âŒ ì„¤ì • í‘œì‹œ ì‹¤íŒ¨: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Ollama RAG Interface í™˜ê²½ ë³€ìˆ˜ ì„¤ì •")
    print("=" * 50)
    
    while True:
        print("\nğŸ“‹ ë©”ë‰´:")
        print("1. env.settings íŒŒì¼ ìƒì„±")
        print("2. í™˜ê²½ ë³€ìˆ˜ ì»¤ìŠ¤í„°ë§ˆì´ì¦ˆ")
        print("3. ì„¤ì • ê²€ì¦")
        print("4. í˜„ì¬ ì„¤ì • í‘œì‹œ")
        print("5. ì¢…ë£Œ")
        
        choice = input("\nì„ íƒí•˜ì„¸ìš” (1-5): ").strip()
        
        if choice == '1':
            create_env_file()
        elif choice == '2':
            customize_env_file()
        elif choice == '3':
            validate_env_file()
        elif choice == '4':
            show_current_config()
        elif choice == '5':
            print("ğŸ‘‹ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. 1-5 ì¤‘ì—ì„œ ì„ íƒí•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main() 